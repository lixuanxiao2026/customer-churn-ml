{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 â€” Modeling\n",
    "\n",
    "**Objective:** Train and compare multiple models with cross-validation and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/churn_features.csv\")\n",
    "if \"Churn\" not in df.columns and df.shape[1] > 0:\n",
    "    df = pd.read_csv(\"../data/raw/churn-bigml-20_raw.csv\")\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    df[\"International plan\"] = (df[\"International plan\"] == \"Yes\").astype(int)\n",
    "    df[\"Voice mail plan\"] = (df[\"Voice mail plan\"] == \"Yes\").astype(int)\n",
    "    df = pd.get_dummies(df, columns=[\"State\"], drop_first=True)\n",
    "    df[\"Churn\"] = df[\"Churn\"].astype(int)\n",
    "    X = df.drop(columns=[\"Churn\"]).select_dtypes(include=[np.number])\n",
    "    y = df[\"Churn\"]\n",
    "    X = pd.DataFrame(StandardScaler().fit_transform(X), columns=X.columns)\n",
    "else:\n",
    "    X = df.drop(columns=[\"Churn\"])\n",
    "    y = df[\"Churn\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training (Multiple Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    cv_score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"roc_auc\")\n",
    "    results[name] = {\"model\": model, \"cv_auc_mean\": cv_score.mean(), \"cv_auc_std\": cv_score.std()}\n",
    "    print(f\"{name}: CV AUC = {cv_score.mean():.3f} (+/- {cv_score.std():.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross-Validation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_summary = pd.DataFrame([{\"Model\": k, \"CV AUC Mean\": v[\"cv_auc_mean\"], \"CV AUC Std\": v[\"cv_auc_std\"]} for k, v in results.items()])\n",
    "cv_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parameter Tuning (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Example: tune Random Forest\n",
    "param_grid = {\"n_estimators\": [50, 100, 200], \"max_depth\": [5, 10, None]}\n",
    "rf_cv = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring=\"roc_auc\")\n",
    "rf_cv.fit(X_train, y_train)\n",
    "print(\"Best params:\", rf_cv.best_params_)\n",
    "print(\"Best CV AUC:\", rf_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Models for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "for name, data in results.items():\n",
    "    fname = name.lower().replace(\" \", \"_\") + \".pkl\"\n",
    "    joblib.dump(data[\"model\"], f\"../models/{fname}\")\n",
    "print(\"Models saved to models/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "- **Fair comparison:** Same train/test split, same features\n",
    "- **No overfitting:** Cross-validation used; tune on train only\n",
    "- **Models:** Logistic Regression, Random Forest, XGBoost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
